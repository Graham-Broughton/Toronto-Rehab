{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport os\nimport pickle\nfrom pdb import set_trace\n\ndef save_obj(obj, name ):\n    with open(name + '.pkl', 'wb') as f:\n        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n        f.close()\ndef load_obj(name):\n    with open(name + '.pkl', 'rb') as f:\n        return pickle.load(f)\n\n\nrootdir = \"/kaggle/input/toronto-robot-stroke-posture-dataset/\"\n\nos.chdir(rootdir + 'data_new')\nsubjects = [name for name in os.listdir(\".\") if os.path.isdir(name)]\n\njoints_sel = range(1,26) #select the desired joint numbers. ref: https://msdn.microsoft.com/en-us/library/microsoft.kinect.jointtype.aspx # SH 2023-01-04: Looks like joints numbers are here because of product updates: https://learn.microsoft.com/en-us/azure/kinect-dk/body-joints\ntotal_joint_num = 25 # From kaggle data card: \"Each file contains three columns made by stacking many 25x3 matrices vertically. The 25 rows correspond to the Kinect joint indices.\"\ninvert_data = True\n\nHsubNames = []\nHlbl_set  = []\nHdata_set = []\n\nPsubNames = []\nPlbl_set  = []\nPdata_set = []\n\nfor sub in subjects:\n    print('==========================='+sub+'============================')\n    os.chdir(rootdir+'data_new'+'/'+sub)\n    tasks = [name for name in os.listdir('.') if os.path.isdir(name)]\n    \n    # SH 2023-01-04: initialize empty array for subsequent appending of data for each task\n    lbl = np.empty([0,1])\n    data = np.empty([0,3*len(joints_sel)]) \n    \n    \"\"\" Load data and labels\"\"\"\n    for task in tasks:\n        print(task)\n        fname = rootdir + 'data_new/' + sub + '/'+ task+'/'+'Joint_Positions.csv'\n        if os.path.isfile(fname):\n            print('loading '+ task + ' ')\n            data_loaded = np.loadtxt(open(fname),delimiter=\",\") # Load data from a text file. In this case, it's a csv file.\n            frame_num = int(len(data_loaded)/total_joint_num) # Number of frames in the data file. From kaggle data card: \"Each file contains three columns made by stacking many 25x3 matrices vertically. \n            features = np.empty((frame_num, 3*len(joints_sel))) # SH 2023-01-04: Return a new array of given shape and type, without initializing entries. Shape = (number of frames, 3 * number of joints)\n            for index, row in enumerate(data_loaded):\n                f = index // total_joint_num # SH 2023-01-04: Get the frame number\n                r = index % total_joint_num # SH 2023-01-04: Get the joint number (i.e. the row number in that video frame)\n                \n                # SH 2023-01-04: Populate the features array with the appropriate data. \n                    # First/left third of the columns is for x coordinates, middle third is for z coordinates, right third is for y coordinates.\n                    # Each row corresponds to one frame\n                if r in joints_sel: \n                    \"\"\" x: flip the joinst if necessary \"\"\"\n                    if invert_data and 'L' in task:\n                        features[f, joints_sel.index(r)] = -row[0]\n                    else:\n                        features[f, joints_sel.index(r)] = row[0]\n                    \"\"\" z \"\"\"\n                    features[f, joints_sel.index(r) + len(joints_sel)] = row[1]\n                    \"\"\" y \"\"\"\n                    features[f, joints_sel.index(r) + 2 * len(joints_sel)] = row[2]\n        else:\n            print(task + ' doesn\\'t exist')\n        #=================load labels ===================================\n        fname = rootdir + 'data_new/' + sub + '/' + task + '/' + 'Labels.csv'\n        if os.path.isfile(fname):\n            print('loading ' + task + ' labels')\n            labels = np.loadtxt(open(fname), delimiter = \",\")\n            if len(labels) != len(features):\n                \"lengths don't match\"\n                set_trace()\n        \n        # SH 2023-01-04: Concatenate data from all tasks for the participant. Not sure why as this seems to make analysis more complicated.\n        data = np.concatenate((data,features),axis=0)  \n        lbl = np.concatenate((lbl, labels.reshape(-1,1)), axis = 0)\n        \n    \"\"\" Assign data and labels to healthy or patients\"\"\"\n    if sub[0] == 'H':\n        HsubNames.append(sub)\n        Hdata_set.append(data)\n        Hlbl_set.append(lbl)\n    elif sub[0] == 'P':\n        PsubNames.append(sub)\n        Pdata_set.append(data)\n        Plbl_set.append(lbl)\n\nH_data = np.vstack(Hdata_set)\nH_labels = np.vstack(Hlbl_set)\nH_sub = []\nfor ii, lbl in enumerate(Hlbl_set):\n    H_sub.extend([HsubNames[ii]*lbl.shape[0]])\nH_sub_ids = np.stack(H_sub)\n\nP_data = np.vstack(Pdata_set)\nP_labels = np.vstack(Plbl_set)\nP_sub = []\nfor ii, lbl in enumerate(Plbl_set):\n    P_sub.extend([PsubNames[ii]]*lbl.shape[0])\nP_sub_ids = np.stack(P_sub)","metadata":{"execution":{"iopub.status.busy":"2023-01-04T05:21:12.315499Z","iopub.execute_input":"2023-01-04T05:21:12.315901Z","iopub.status.idle":"2023-01-04T05:21:31.581664Z","shell.execute_reply.started":"2023-01-04T05:21:12.315871Z","shell.execute_reply":"2023-01-04T05:21:31.580283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_dir = '/kaggle/working/'\nos.chdir(output_dir)\nos.mkdir('stroke_data')\n!ls","metadata":{"execution":{"iopub.status.busy":"2023-01-04T05:37:15.081490Z","iopub.execute_input":"2023-01-04T05:37:15.081865Z","iopub.status.idle":"2023-01-04T05:37:15.354260Z","shell.execute_reply.started":"2023-01-04T05:37:15.081835Z","shell.execute_reply":"2023-01-04T05:37:15.352681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the data as pickles\nos.chdir('stroke_data')\nsave_obj(H_data,\"H_data\")#only using left hand\nsave_obj(H_labels,\"H_labels\")#only using left hand\nsave_obj(H_sub_ids,\"H_sub_ids\")#participant number\nsave_obj(P_data,\"P_data\")#only using left hand\nsave_obj(P_labels,\"P_labels\")#only using left hand\nsave_obj(P_sub_ids,\"P_sub_ids\")#participant number","metadata":{"execution":{"iopub.status.busy":"2023-01-04T05:38:20.937851Z","iopub.execute_input":"2023-01-04T05:38:20.938259Z","iopub.status.idle":"2023-01-04T05:38:20.990986Z","shell.execute_reply.started":"2023-01-04T05:38:20.938223Z","shell.execute_reply":"2023-01-04T05:38:20.989311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_data = load_obj('P_data')\nprint(p_data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-01-04T05:42:49.772591Z","iopub.execute_input":"2023-01-04T05:42:49.772974Z","iopub.status.idle":"2023-01-04T05:42:49.784448Z","shell.execute_reply.started":"2023-01-04T05:42:49.772943Z","shell.execute_reply":"2023-01-04T05:42:49.783662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"load_obj('P_labels').shape","metadata":{"execution":{"iopub.status.busy":"2023-01-04T05:45:26.745363Z","iopub.execute_input":"2023-01-04T05:45:26.746096Z","iopub.status.idle":"2023-01-04T05:45:26.754092Z","shell.execute_reply.started":"2023-01-04T05:45:26.746061Z","shell.execute_reply":"2023-01-04T05:45:26.752408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h_data = load_obj('H_data')\nprint(type(h_data))\nprint(h_data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-01-04T05:44:25.591501Z","iopub.execute_input":"2023-01-04T05:44:25.591876Z","iopub.status.idle":"2023-01-04T05:44:25.635993Z","shell.execute_reply.started":"2023-01-04T05:44:25.591845Z","shell.execute_reply":"2023-01-04T05:44:25.634457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"load_obj('H_labels').shape","metadata":{"execution":{"iopub.status.busy":"2023-01-04T05:45:15.502960Z","iopub.execute_input":"2023-01-04T05:45:15.503348Z","iopub.status.idle":"2023-01-04T05:45:15.510986Z","shell.execute_reply.started":"2023-01-04T05:45:15.503317Z","shell.execute_reply":"2023-01-04T05:45:15.509485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SH 2023-01-04 20:38: Next step: Create a function to select data from a given task","metadata":{},"execution_count":null,"outputs":[]}]}
